{'error': {'message': "This model's maximum context length is 128000 tokens. However, you requested 129476 tokens (125380 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}