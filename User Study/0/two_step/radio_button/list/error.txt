{'error': {'message': "This model's maximum context length is 128000 tokens. However, your messages resulted in 154087 tokens. Please reduce the length of the messages.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}