{'error': {'message': "This model's maximum context length is 128000 tokens. However, you requested 129441 tokens (125345 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}