{'error': {'message': "This model's maximum context length is 128000 tokens. However, you requested 130875 tokens (126779 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}